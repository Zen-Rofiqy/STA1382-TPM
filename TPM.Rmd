---
title: "TPM"
author: "Angga Fathan Rofiqy"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  rmdformats::downcute:
    self_contained: true
    thumbnails: false
    lightbox: true
    gallery: true
    highlight: tango
    code_folding: show
    toc_depth: 3
    number_sections: false
    toc_float:
      collapsed: true
      smooth_scroll: true
    fig_caption: true
pkgdown:
  as_is: true
---

```{r message=FALSE, warning=FALSE, include=FALSE}
#                      -=( Install & Load Package Function )=-
install_load <- function (package1, ...)  {   

   # convert arguments to vector
   packages <- c(package1, ...)

   # start loop to determine if each package is installed
   for(package in packages){

       # if package is installed locally, load
       if(package %in% rownames(installed.packages()))
          do.call('library', list(package))

       # if package is not installed locally, download, then load
       else {
          install.packages(package)
          do.call("library", list(package))
       }
   } 
}

install_load("DT","dplyr","ggplot2","gridExtra","MASS","tree","rio")

theme1.1 <- list(
  geom_hline(yintercept = 0, size = 1, colour="#333333"),
  theme(axis.text.x = element_text(angle = 45, hjust = 1, 
                                   margin = margin(b = 10, t=-20)),
        axis.text.y = element_text(vjust = 0.5, face = "bold", 
                                   margin = margin(l = 20, r = 0)),
        plot.title = element_text(hjust = 0.5, face = "bold"),
        text = element_text(size = 30),
        plot.subtitle = element_text(hjust = 0.5),
        panel.background = element_rect(fill = 'transparent'),
        plot.background = element_rect(fill='transparent', color=NA),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank()
        ) 
)
```

```{r setup, include=FALSE, echo=FALSE, warning=FALSE, message = FALSE}
require("knitr")
opts_knit$set(root.dir = "C:/Users/Fathan/Documents/Obsidian Vault/2. Kuliah/Smt 6/2. Teknik Pembelajaran Mesin/Project")

#Export chart
export.chart <- "C:/Users/Fathan/Documents/Obsidian Vault/2. Kuliah/Smt 6/2. Teknik Pembelajaran Mesin/Project/Chart"
```

> <mark style="background-color: #91CCDB">**Code/Syntax :** [File.rmd](https://github.com/Zen-Rofiqy/STA1382-TPM/blob/main/TMP.Rmd) </mark>

# Kuliah 1

> **Penyiapan Data (R)**

## 1. **Statistik Deskriptif**

**Daftar variabel :**

-   `Pregnancies` : Number of times pregnant

-   `Glucose` : Plasma glucose concentration a 2 hours in an oral glucose tolerance test

-   `BloodPressure` : Diastolic blood pressure (mm Hg)

-   `SkinThickness` : Triceps skin fold thickness (mm)

-   `Insulin` : 2-Hour serum insulin (mu U/ml)

-   `BMI` : Body mass index (weight in kg/(height in m)\^2)

-   `DiabetesPedigreeFunction` : Diabetes pedigree function

-   `Age` : Age (years)

-   `Outcome` : Class variable (0 or 1) 268 of 768 are 1 (diabetes), the others are 0 (tidak diabetes)

```{r}

data <- read.csv('/kaggle/input/pima-indians-diabetes-database/diabetes.csv')
summary(data)
head(data, 10)
```

```{r}
library(httr)

# Gantilah 'your_username' dan 'your_authkey' dengan informasi akun Kaggle Anda
username <- "zenrofiqy"
authkey <- "594416325ca5f1711fb40cb5e1795b8c"

url <- "https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database/download?datasetVersionNumber=1"



# Lakukan permintaan GET dengan autentikasi
dataset <- httr::GET(url, httr::authenticate(username, authkey, type = "basic"))

# Simpan file CSV ke tempat sementara
temp <- tempfile(fileext = ".csv")
writeBin(dataset$content, temp)

# Baca data CSV langsung
data <- read.csv(temp)

# Hapus file sementara
file.remove(temp)

View(data)

```

# Kuliah 3

```{r}
str(cpus)
cpus.ltr <- tree(log10(perf) ~ syct + mmin + mmax + chmin + chmax, data=cpus)
plot(cpus.ltr)
text(cpus.ltr)

summary(cpus.ltr)
```

# Kuliah 4

Entropy

```{r}
p <- 0.6919
E <- function(p) -p * log2(p) - (1-p) * log2(1-p)
E(p)
E(p)
```

Information Gain

```{r}
IG <- 
```

```{r}
info_gain <- function(D, A) {
  H_D <- H(D[[A]]) 
  
  values <- unique(D[[A]])
  D_v <- split(D, D[[A]]) 
  
  H_D_A <- sum(sapply(D_v, function(x) length(x)/nrow(D) * H(x[[A]]))) 
  
  return(H_D - H_D_A)
}

H <- function(D) {
  p <- table(D)/length(D) 
  return(sum(-p*log2(p))) 
}



# Data 
data <- data.frame(
  outcome = c("Yes","Yes","No","Yes","No","Yes"),
  attribute = c("Tall","Tall","Tall","Short","Short","Short")
)

# Hitung entropy sebelum split
H_D <- H(data$outcome) 
H_D

# Split data berdasarkan attribute
D_v <- split(data, data$attribute)

# Hitung weighted entropy setelah split
H_D_A <- sum(sapply(D_v, function(x) length(x)/nrow(data) * H(x$outcome)))
H_D_A

# Hitung information gain
info_gain(data, "attribute")
```

```{r}
# Tabel kontingensi  
table <- matrix(c(6,3,2,1), nrow = 2, byrow = TRUE)
table

# Hitung total data 
N <- sum(table)  

# Hitung entropy sebelum split
H_D <- sum(-table/N * log2(table/N))

# Buat tabel kontingensi terpisah untuk setiap atribut
table_A1 <- matrix(c(6,2), nrow = 1)
table_A2 <- matrix(c(3,1), nrow = 1)

# Hitung weighted entropy
H_A <- sum(table[,1]/N * apply(cbind(table_A1, table_A2), 1, function(x) sum(-x/sum(x)*log2(x/sum(x))))) 

# Hitung information gain
IG <- H_D - H_A
IG
```

```{r}
# Tabel kontingensi  
table <- matrix(c(561, 27,
                  51.75, 2.49,
                  95.41, 4.59,
                  74.8, 8.08,
                  189, 307), nrow = 2, byrow = TRUE)
table

# Hitung total data 
N <- sum(table)  

# Hitung entropy sebelum split
H_D <- sum(-table/N * log2(table/N))

# Buat tabel kontingensi terpisah untuk setiap atribut
table_A1 <- matrix(c(6,2), nrow = 1)
table_A2 <- matrix(c(3,1), nrow = 1)

# Hitung weighted entropy
H_A <- sum(table[,1]/N * apply(cbind(table_A1, table_A2), 1, function(x) sum(-x/sum(x)*log2(x/sum(x))))) 

# Hitung information gain
IG <- H_D - H_A
IG
```

Ilustrasi

```{r}
##Classification Tree
propensity <- read.csv("D:/datatree01.csv", sep=";", header=TRUE)
tertarik <- factor(propensity$Tertarik.Beli., levels = 0:1, labels = c("Tidak", "Tertarik")) 
jk <- factor(propensity$Jenis.Kelamin,   levels = 0:1, labels = c("Perempuan", "Laki-Laki")) 
kota <- factor(propensity$Tinggal.di.Kota, levels = 0:1, labels = c("Tidak", "Ya"))
single <- factor(propensity$Single, levels = 0:1, labels = c("Menikah", "Single")) 
merokok <- factor(propensity$Perokok, levels = 0:1, labels = c("Tidak", "Ya")) 
budget <- propensity$Budget
usia <-propensity$usia
```

```{r}
library(rpart)
model.01 <- rpart(tertarik ~ jk + kota + single + usia + merokok + budget,
method="class", control = rpart.control(minsplit = 100))
model.01
```

```{r}
library(rpart.plot)
rpart.plot(model.01, extra=6)
```

```{r}
rpart.plot(model.01, extra=1)
```

```{r}
model.02 <- rpart(tertarik ~ jk + kota + single + usia + merokok + budget,
method="class", control = rpart.control(minsplit = 50))
rpart.plot(model.02, extra=6)
```

```{r}
data.training <- data.frame(jk, kota, single, usia, merokok, budget, tertarik) 
prob.prediksi.02 <- predict(model.02, newdata=data.training)
head(prob.prediksi.02)
```

```{r}
prediksi.02 <- factor(ifelse(prob.prediksi.02[,2] > 0.5, 1, 0),
levels = 0:1, labels = c("Tidak", "Te r t a r i k "))


library(caret)
confusionMatrix(prediksi.02, tertarik)
```

```{r}
prediksi.02 <- factor(ifelse(prob.prediksi.02[,2] > 0.6, 1, 0),
levels = 0:1, labels = c("Tidak", "Te r t a r i k "))

confusionMatrix(prediksi.02, tertarik)
```

```{r}
prediksi.02 <- factor(ifelse(prob.prediksi.02[,2] > 0.3, 1, 0),
levels = 0:1, labels = c("Tidak", "Te r t a r i k "))

confusionMatrix(prediksi.02, tertarik)
```

# Praktikum 4

## Library

```{r message=FALSE, warning=FALSE}
#install.packages("tensorflow")
#install.packages("keras")

#library("reticulate")
#virtualenv_create("r-reticulate2", python = install_python())
#tensorflow::install_tensorflow()
#keras::install_keras()

# Delete Installation
#wunlink("~/.virtualenvs/r-tensorflow", recursive = TRUE)
```

## Model Klasifikasi NN

### Data

```{r}
dt4 <- read.csv("https://raw.githubusercontent.com/Zen-Rofiqy/STA1382-TPM/main/Materi/Prak%2004/ObesityDataSet.csv", stringsAsFactors = TRUE)
datatable(dt4)
```

```{r}
str(dt4)
```

### Cek Missing Value

```{r}
colSums(is.na(dt4))
```

### Encoding Peubah Kategorik

```{r message=FALSE, warning=FALSE}
library(tensorflow); library(keras); library(caret)
# One-Hot Encoder
for(i in 1:(dim(dt4)[2] - 1)){
  if(is.factor(dt4[,i]) == TRUE){
    dt4[,i] <- to_categorical(as.integer(dt4[,i]) - 1)
  }
}

# Contoh Hasil One-Hot Encoder
head(dt4$MTRANS)
```

### Splitting Data & Scaling

```{r}
set.seed(123)

# Train-Testing Split
train.index <- createDataPartition(dt4$NObeyesdad, p = 0.8, list = F)
train <- dt4[train.index, ]
test <- dt4[-train.index, ]

# Feature Scaling (Min-Max)
preprocessParams <- preProcess(train[, -17], method = "range")
train_X <- as.matrix(predict(preprocessParams, train[, -17]))
test_X <- as.matrix(predict(preprocessParams, test[, -17]))

# Encoding Variabel Respons
train_y <- to_categorical(as.integer(train[, 17])-1)
test_y <- to_categorical(as.integer(test[, 17])-1)
```

## Model 1 **(1 hidden layer)**

```{r message=FALSE, warning=FALSE}
# Arsitektur Model
model <- keras_model_sequential() %>%
  layer_dense(units = 64, activation = "relu", input_shape = ncol(train_X)) %>%
  layer_dense(units = ncol(train_y), activation = "softmax")

# Kompilasi Model
model %>% compile(
  loss = "categorical_crossentropy",
  optimizer = "adam",
  metrics = c("accuracy")
)

print(model)
```

```{r message=FALSE, warning=FALSE}
# Training Model
history <- model %>% fit(
  train_X, train_y,
  shuffle = T,
  epochs = 100,
  batch_size = 32, 
  validation_split = 0.2
)
```

```{r dpi=300, fig.height = 7, fig.width = 10, fig.align = "center", message = FALSE, warning=FALSE}
plot(history)
```

```{r}
# Evaluasi Model dengan data Test
scores <- model %>% evaluate(test_X, test_y)
print(scores)
```

### Prediksi Model

```{r}
# Prediksi dalam bentuk peluang
pred <- predict(model, test_X)
head(pred)
```

```{r}
# Prediksi Label
label_pred <- apply(pred, 1, which.max)
label_pred
```

```{r}
# Nilai aktual
label_true <- as.integer(test$NObeyesdad)
label_true
```

### Evaluasi Model

```{r}
confusionMatrix(as.factor(label_true), as.factor(label_pred))
```

## Model 2 **(2 Hidden layers + dropout)**

```{r}
# Membuat model neural network dengan 2 hidden layer
model <- keras_model_sequential() %>%
  layer_dense(units = 128, activation = "relu", input_shape = ncol(train_X)) %>%
  layer_dropout(0.2) %>%
  layer_dense(units = 64, activation = "relu") %>%
  layer_dropout(0.2) %>%
  layer_dense(units = ncol(train_y), activation = "softmax")

# Mengkompilasi model
model %>% compile(
  loss = "categorical_crossentropy",
  optimizer = "adam",
  metrics = c("accuracy")
)

# Melakukan tahapan pelatihan model
history <- model %>% fit(
  train_X, train_y,
  shuffle = T,
  epochs = 100,
  batch_size = 32,
  validation_split = 0.2, 
  verbose = F       # tidak menampilkan teks ouput pada setiap epoch
)

print(model)
```

```{r dpi=300, fig.height = 7, fig.width = 10, fig.align = "center", message = FALSE, warning=FALSE}
plot(history)
```

```{r}
# Mengevaluasi model menggunakan data uji
scores <- model %>% evaluate(test_X, test_y)
print(scores)
```

### Prediksi Model

```{r}
prediksi <- predict(model, test_X)
head(prediksi)
```

Untuk menentukan kategori dengan peluang terbesar kita dapat menggunakan fungsi `which.max` yang dikombinasikan dengan fungsi `apply`.

```{r}
label_pred <- apply(prediksi, 1, which.max)
label_pred
```

```{r}
label_true <- as.integer(test$NObeyesdad)
label_true
```

### Evaluasi Model

```{r}
confusionMatrix(as.factor(label_true), as.factor(label_pred))
```

## Save Model

```{r message=FALSE, warning=FALSE}
# Menyimpan model dalam format HDF5
model %>% save_model_hdf5("model_nn.h5")

# Memuat model dari file HDF5
model <- load_model_hdf5("model_nn.h5")

print(model)
```

## Model 3 (**2 hidden layer + dropout + callback)**

```{r}
# Multiclass Model dengan 2 hidden layers + dropout + checkpoint + earlyStopping

model.3 <- keras_model_sequential() %>%
           layer_dense(units = 120, activation = "relu", input_shape = ncol(train_X)) %>%
           layer_dropout(0.2) %>%
           layer_dense(units = 100, activation = "relu") %>%
           layer_dropout(0.1) %>%
           layer_dense(units = ncol(train_y), activation = "softmax")


# menentukan nama dan path file untuk penyimpanan model
filepath <- "model_check_x.keras"

# mengatur kriteria checkpoint
# simpan model jika memperoleh skor terbaik
checkpoint <- callback_model_checkpoint(
    filepath=filepath,
    monitor="val_accuracy",
    save_best_only=TRUE,
    mode="max",
    verbose=1,
)

# mengatur kondisi untuk early stopping
early_stopping <- callback_early_stopping(
    monitor="val_accuracy",
    patience=30,
    verbose=1,
)

# kompilasi model
model.3 %>% compile(
  loss = "categorical_crossentropy",
  optimizer = "adam",
  metrics = c("accuracy")
)

# melatih model
history <- model.3 %>% fit(
  train_X, train_y,
  shuffle = T,
  epochs = 200,
  batch_size = 64,
  # validation_split = 0.2, # atau
  validation_data = list(test_X, test_y),
  callbacks=list(checkpoint, early_stopping),
)
```

```{r}
summary(model.3)
```

```{r dpi=300, fig.height = 7, fig.width = 10, fig.align = "center", message = FALSE, warning=FALSE}
plot(history)
```

```{r}
# evaluasi model
scores <- model.3 %>% evaluate(test_X, test_y)
print(scores)
```

## Model Regresi 

```{r}
data.ab <-  read.csv("https://raw.githubusercontent.com/Zen-Rofiqy/STA1382-TPM/main/Materi/Prak%2004/abalone.csv", stringsAsFactors = TRUE)
datatable(data.ab)
```

```{r}
str(data.ab)
```

```{r}
# Cek Missing Value
colSums(is.na(data.ab))
```

### Feature Engineering 

```{r}
# Menambahkan Kolom 'Age'
data.ab$Age <- data.ab$Rings + 1.5

# Menghapus Kolom 'Rings'
data.ab$Rings <- NULL

# One-Hot Encoding Kolom 'Sex'
data.ab$Sex <- to_categorical(as.integer(data.ab$Sex) - 1)
```

### Splitting & Scaling

```{r}
set.seed(123)

train.index <- createDataPartition(data.ab$Age, p = 0.8, list = FALSE)
train <- data.ab[train.index, ]
test <- data.ab[-train.index, ]

# Melakukan Feature Scaling min max (0, 1)
preprocessParams <- preProcess(train[, -9], method=c("range"))
train_X <- as.matrix(predict(preprocessParams, train[, -9]))
test_X <- as.matrix(predict(preprocessParams, test[, -9]))

train_y <- train[, 9]
test_y <- test[, 9]
```

### Pemodelan

```{r message=FALSE, warning=FALSE}
# Membuat model neural network dengan 2 hidden layer
model <- keras_model_sequential() %>%
  layer_dense(units = 64, activation = "relu", input_shape = ncol(train_X)) %>%
  layer_dropout(0.3) %>%
  layer_dense(units = 64, activation = "relu") %>%
  layer_dropout(0.3) %>%
  layer_dense(units = 1, activation = "linear")

# Mengkompilasi model
model %>% compile(
  loss = "mean_squared_error",
  optimizer = "adam",
  metrics = list("mean_squared_error", "mean_absolute_error")
)

# Melakukan tahapan pelatihan model
history <- model %>% fit(
  train_X, train_y,
  shuffle = T,
  epochs = 50,
  batch_size = 32,
  validation_split = 0.2
)
print(model)
```

```{r dpi=300, fig.height = 15, fig.width = 10, fig.align = "center", message = FALSE, warning=FALSE}
plot(history)
```

```{r}
print(model)
```

### Prediksi

```{r}
prediksi <- predict(model, test_X)
head(prediksi)
```

### Evaluasi Model

```{r}
# Mengevaluasi model menggunakan data uji
scores <- model %>% evaluate(test_X, test_y)
print(scores)
```

```{r}
keras_train <- model %>% predict(train_X)
keras_test <- model %>% predict(test_X)
# Training Evaluation
postResample(keras_train[,1], train$Age)
# Testing Evaluation
postResample(keras_test[,1], test$Age)
```

# Kuliah 5

## Sy ntax Kuliah {.tabset}

### **Binary classification**

```{r}
library(neuralnet)
nn <- neuralnet(Species=="setosa" ~Petal.Length  +Petal.Width, iris, 
                linear.output = FALSE)
print(nn) 
plot(nn)
```

### **Multiclass classification**

```{r}
nn2 <- neuralnet(Species ~ Petal.Length + Petal.Width, iris, linear.output = FALSE) 
names(nn2)
nn2$act.fct 
print(nn2)
plot(nn2)
```

### **Custom activation function**

```{r}
softplus <- function(x) log(1 + exp(x))
nn3  <-  neuralnet((Species  ==  "setosa")  ~  Petal.Length  +  Petal.Width,  iris, 
linear.output = FALSE, hidden = c(3, 2), act.fct = softplus)
print(nn3) 
plot(nn3)
```

## Tugas

```{r}
f.act <- function(x) log(1 + exp(x))

neuron <- function(x1, x2, x3){
  h1 = .5*x1 - .2*x2 - .1*x3
  h1 = f.act(h1)
  
  h2 = .3*x1 + .1*x2 + .6*x3
  h2 = f.act(h2)
  
  out = .2*h1 - .1*h2 
  out = f.act(out)
  return(out)
}

r1 <- neuron(1, 1, 2)
r2 <- neuron(2, 3, 1)
r3 <- neuron(2, 1, 1) 

y <- c(2, 3, 1)

y_ <- data.frame(r1, r2, r3)
print(y_)

n <- 3
mse <- 1/n * sum((y - y_)^2)
print(mse)
```

# Referensi 

Alkahfi, C. (Feb 19, 2023). Model Neural Network pada R Menggunakan Library Keras. Retrieved from: <https://sainsdata.id/uncategorized/2630/model-neural-network-pada-r-menggunakan-library-keras/>

Keras R Documentation : <https://www.rdocumentation.org/packages/keras/versions/2.11.0>

Pichler, M. (June 6, 2018). An Introduction to machine learning with Keras in R. Retrieved from: <https://www.r-bloggers.com/2018/06/an-introduction-to-machine-learning-with-keras-in-r/>

Sadik, K. (2022). Artificial Neural Network [Slide Kuliah STA1582 Pembelajaran Mesin Statistika IPB University]

Sallan, J. M. (May 17, 2020). Neural networks. Retrieved from: <https://rpubs.com/jmsallan/nn_intro>
